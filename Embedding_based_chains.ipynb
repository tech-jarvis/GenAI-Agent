{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fahad-Aslam/LangChain/blob/main/Embedding_based_chains.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AreJQEikeqbd"
      },
      "source": [
        "#Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDq0Vsj8ekrM"
      },
      "outputs": [],
      "source": [
        "!pip install langchain huggingface_hub > /dev/null\n",
        "!pip install google-search-resultsfrom langchain import HuggingFaceHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9vZtIbvfGDg"
      },
      "outputs": [],
      "source": [
        "pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CimZomEEexTB"
      },
      "outputs": [],
      "source": [
        "from langchain import HuggingFaceHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxR3y0Bxe0co"
      },
      "outputs": [],
      "source": [
        "huggingfacehub_api_token=\"huggingface_api_token\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iN_9JHdze0Yh"
      },
      "outputs": [],
      "source": [
        "# Falcon 7Billion Chat-model\n",
        "\n",
        "\n",
        "# # Falcon 7Billion Chat-model\n",
        "# repo_id=\"TheBloke/Nous-Hermes-13B-GPTQ\"\n",
        "#repo_id=\"TheBloke/Llama-2-13B-GGML\"\n",
        "repo_id = \"tiiuae/falcon-7b-instruct\"\n",
        "# repo_id2 = \"google/flan-t5-xxl\"\n",
        "llm = HuggingFaceHub(huggingfacehub_api_token=huggingfacehub_api_token,\n",
        "                     repo_id=repo_id,\n",
        "                     model_kwargs={\"temperature\": 0.5,\n",
        "                                   \"max_new_tokens\":200,\n",
        "                                  #  \"min_length\": 200,\n",
        "                                   \"max_length\": 200,\n",
        "                                   \"num_return_sequences\":1\n",
        "                                  #  \"top_k\": 50,\n",
        "                                  #  \"top_p\": .95,\n",
        "                                  #  \"do_sample\": True,\n",
        "                                  #  \"early_stopping\": False,\n",
        "                                  #  \"num_beams\": 1,\n",
        "                                  #  \"no_repeat_ngram_size\": 3\n",
        "                                   })\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7q47GZhekXp"
      },
      "source": [
        "#Very simple sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSbBOzqkeTqQ",
        "outputId": "b82c8611-a406-46a7-c950-b97d8517755e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, openapi-schema-pydantic, langsmith, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.5.13 langchain-0.0.238 langsmith-0.0.12 marshmallow-3.20.1 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGQTSbJQeXWb"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wf3xp_fwebOl"
      },
      "outputs": [],
      "source": [
        "# This is an LLMChain to write a synopsis given a title of a play.\n",
        "llm = llm\n",
        "\n",
        "template = \"\"\"You are a playwright. Given the title of play, it is your job to write a synopsis for that title.\n",
        "\n",
        "Title: {title}\n",
        "Playwright: This is a synopsis for the above play:\"\"\"\n",
        "prompt_template = PromptTemplate(input_variables=[\"title\"], template=template)\n",
        "synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z651xJe3ee3k"
      },
      "outputs": [],
      "source": [
        "# This is an LLMChain to write a review of a play given a synopsis.\n",
        "llm = llm\n",
        "template = \"\"\"You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.\n",
        "\n",
        "Play Synopsis:\n",
        "{synopsis}\n",
        "Review from a New York Times play critic of the above play:\"\"\"\n",
        "prompt_template = PromptTemplate(input_variables=[\"synopsis\"], template=template)\n",
        "review_chain = LLMChain(llm=llm, prompt=prompt_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHSb_KejfQ6y"
      },
      "outputs": [],
      "source": [
        "# This is the overall chain where we run these two chains in sequence.\n",
        "from langchain.chains import SimpleSequentialChain\n",
        "overall_chain = SimpleSequentialChain(chains=[synopsis_chain, review_chain], verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6arn06wfSr-",
        "outputId": "ce03d7f7-f767-432b-dccd-b0295c8e8fac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m\n",
            "\n",
            "The play opens at sunset on a beach, where a man and a woman meet by chance. As the sun fades away and the waves crash against the shore, they share a connection that brings them together. However, their moment of happiness is short lived as an unexpected tragedy occurs. As the play unfolds, the couple struggles to come to terms with their loss, ultimately leading to a heartwarming and emotional conclusion.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m\n",
            "\n",
            "The emotional resonance of this play is palpable, as it delicately explores the fragility of human connection and the devastating impact of sudden loss. The performances from the two leads are outstanding, and their palpable chemistry is a joy to behold. The playwright has crafted a touching and thought-provoking piece that will leave you feeling moved and inspired.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "review = overall_chain.run(\"Tragedy at sunset on the beach\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xxn5Igo3gaBq"
      },
      "source": [
        "#2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAMPKWz7fT5j"
      },
      "outputs": [],
      "source": [
        "# This is an LLMChain to write a synopsis given a title of a play and the era it is set in.\n",
        "llm = llm\n",
        "template = \"\"\"You are a playwright. Given the title of play and the era it is set in, it is your job to write a synopsis for that title.\n",
        "\n",
        "Title: {title}\n",
        "Era: {era}\n",
        "Playwright: This is a synopsis for the above play:\"\"\"\n",
        "prompt_template = PromptTemplate(input_variables=[\"title\", \"era\"], template=template)\n",
        "synopsis_chain = LLMChain(llm=llm, prompt=prompt_template, output_key=\"synopsis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSjNRv-agcGM"
      },
      "outputs": [],
      "source": [
        "# This is an LLMChain to write a review of a play given a synopsis.\n",
        "llm = llm\n",
        "template = \"\"\"You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.\n",
        "\n",
        "Play Synopsis:\n",
        "{synopsis}\n",
        "Review from a New York Times play critic of the above play:\"\"\"\n",
        "prompt_template = PromptTemplate(input_variables=[\"synopsis\"], template=template)\n",
        "review_chain = LLMChain(llm=llm, prompt=prompt_template, output_key=\"review\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MN73QfYfgf14"
      },
      "outputs": [],
      "source": [
        "# This is the overall chain where we run these two chains in sequence.\n",
        "from langchain.chains import SequentialChain\n",
        "overall_chain = SequentialChain(\n",
        "    chains=[synopsis_chain, review_chain],\n",
        "    input_variables=[\"era\", \"title\"],\n",
        "    # Here we return multiple variables\n",
        "    output_variables=[\"synopsis\", \"review\"],\n",
        "    verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypbrbDvQgh1n",
        "outputId": "00922613-5fdd-40dc-f422-e4e97d9991a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'title': 'Tragedy at sunset on the beach',\n",
              " 'era': 'Victorian England',\n",
              " 'synopsis': '\\n\\nIn a world where social class rules, young artist, Mr. William Turner, falls in love with the married and wealthy Mrs. Catherine More. As their passionate affair unfolds, it becomes clear that their love will have tragic consequences. The play explores themes of forbidden love, societal expectations, and the devastating effects of the rigid class structure. With a gripping plot and poignant performances, Tragedy at Sunset on the Beach is a timeless tale of unrequited love that transcends societal barriers.',\n",
              " 'review': '\\n\\nTragedy at Sunset on the Beach is a gripping, timely tale of forbidden love that transcends societal barriers. With a captivating plot and stellar performances, the play offers a poignant examination of unrequited love, as well as a haunting exploration of class structure. This timeless classic is a must-see for theater-goers seeking a thought-provoking evening of drama.'}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "overall_chain({\"title\":\"Tragedy at sunset on the beach\", \"era\": \"Victorian England\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0-AdCQdg9NG"
      },
      "source": [
        "#Memory in Sequential Chains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_JAt8yjgjCZ",
        "outputId": "629e8a2c-dd53-4c9d-d956-90131f7205b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'title': 'Tragedy at sunset on the beach',\n",
              " 'era': 'Victorian England',\n",
              " 'time': 'December 25th, 8pm PST',\n",
              " 'location': 'Theater in the Park',\n",
              " 'social_post_text': \"\\nAre you ready to experience a timeless classic this holiday season? Join us at the Theater in the Park for #TragedyAtSunset, a gripping tale of unrequited love. Get your tickets now to avoid disappointment. #TragedyAtSunset #TheaterInThePark #HolidayTheater\\n\\nDon't miss this classic play this December. Get your tickets now to experience a timeless tale that transcends societal barriers. #TragedyAtSunset #TheaterInThePark #HolidayTheater\"}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.chains import SequentialChain\n",
        "from langchain.memory import SimpleMemory\n",
        "\n",
        "llm = llm\n",
        "template = \"\"\"You are a social media manager for a theater company.  Given the title of play, the era it is set in, the date,time and location, the synopsis of the play, and the review of the play, it is your job to write a social media post for that play.\n",
        "\n",
        "Here is some context about the time and location of the play:\n",
        "Date and Time: {time}\n",
        "Location: {location}\n",
        "\n",
        "Play Synopsis:\n",
        "{synopsis}\n",
        "Review from a New York Times play critic of the above play:\n",
        "{review}\n",
        "\n",
        "Social Media Post:\n",
        "\"\"\"\n",
        "prompt_template = PromptTemplate(input_variables=[\"synopsis\", \"review\", \"time\", \"location\"], template=template)\n",
        "social_chain = LLMChain(llm=llm, prompt=prompt_template, output_key=\"social_post_text\")\n",
        "\n",
        "overall_chain = SequentialChain(\n",
        "    memory=SimpleMemory(memories={\"time\": \"December 25th, 8pm PST\", \"location\": \"Theater in the Park\"}),\n",
        "    chains=[synopsis_chain, review_chain, social_chain],\n",
        "    input_variables=[\"era\", \"title\"],\n",
        "    # Here we return multiple variables\n",
        "    output_variables=[\"social_post_text\"],\n",
        "    verbose=True)\n",
        "\n",
        "overall_chain({\"title\":\"Tragedy at sunset on the beach\", \"era\": \"Victorian England\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6_hw8GghrL5"
      },
      "source": [
        "#Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_LeAGnPhsdf"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import TransformChain, LLMChain, SimpleSequentialChain\n",
        "# from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.document_loaders import TextLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_ejjg4dhviw"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# documents = TextLoader('/content/drive/MyDrive/finma.txt').load()\n",
        "\n",
        "with open(\"/content/drive/MyDrive/finma.txt\") as f:\n",
        "    state_of_the_union = f.read()\n",
        "\n",
        "print(state_of_the_union)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CI-X6W1GhyOj"
      },
      "outputs": [],
      "source": [
        "def transform_func(inputs: dict) -> dict:\n",
        "    text = inputs[\"text\"]\n",
        "    shortened_text = \"\\n\\n\".join(text.split(\"\\n\\n\")[:3])\n",
        "    return {\"output_text\": shortened_text}\n",
        "\n",
        "\n",
        "transform_chain = TransformChain(\n",
        "    input_variables=[\"text\"], output_variables=[\"output_text\"], transform=transform_func\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-WRx-EBiDyp"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"Summarize this text:\n",
        "\n",
        "{output_text}\n",
        "\n",
        "Summary:\"\"\"\n",
        "prompt = PromptTemplate(input_variables=[\"output_text\"], template=template)\n",
        "llm_chain = LLMChain(llm=llm, prompt=prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCCOrLyHiGN1"
      },
      "outputs": [],
      "source": [
        "sequential_chain = SimpleSequentialChain(chains=[transform_chain, llm_chain])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "6FajhHUHiKwC",
        "outputId": "742fc53f-b988-420f-d86b-f13e22d4ec37"
      },
      "outputs": [],
      "source": [
        "sequential_chain.run(state_of_the_union)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgEG7W_yjWkM"
      },
      "source": [
        "#Router"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFUGHQhsjXKn"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.router import MultiPromptChain\n",
        "# from langchain.llms import OpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqnxB03wjar8"
      },
      "outputs": [],
      "source": [
        "physics_template = \"\"\"You are a very smart physics professor. \\\n",
        "You are great at answering questions about physics in a concise and easy to understand manner. \\\n",
        "When you don't know the answer to a question you admit that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "\n",
        "math_template = \"\"\"You are a very good mathematician. You are great at answering math questions. \\\n",
        "You are so good because you are able to break down hard problems into their component parts, \\\n",
        "answer the component parts, and then put them together to answer the broader question.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSJlG4HTjcJa"
      },
      "outputs": [],
      "source": [
        "prompt_infos = [\n",
        "    {\n",
        "        \"name\": \"physics\",\n",
        "        \"description\": \"Good for answering questions about physics\",\n",
        "        \"prompt_template\": physics_template,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"math\",\n",
        "        \"description\": \"Good for answering math questions\",\n",
        "        \"prompt_template\": math_template,\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQRjx0ZLjdw3"
      },
      "outputs": [],
      "source": [
        "llm = llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWe0G7tdjhNg"
      },
      "outputs": [],
      "source": [
        "destination_chains = {}\n",
        "for p_info in prompt_infos:\n",
        "    name = p_info[\"name\"]\n",
        "    prompt_template = p_info[\"prompt_template\"]\n",
        "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    destination_chains[name] = chain\n",
        "\n",
        "default_chain = ConversationChain(llm=llm, output_key=\"text\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY7VAYk_jr10"
      },
      "source": [
        "####LLMRouterChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wccZ3UNBjicd"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
        "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0SDjHG_jtz-"
      },
      "outputs": [],
      "source": [
        "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
        "destinations_str = \"\\n\".join(destinations)\n",
        "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
        "router_prompt = PromptTemplate(\n",
        "    template=router_template,\n",
        "    input_variables=[\"input\"],\n",
        "    output_parser=RouterOutputParser(),\n",
        "    # handle_parsing_errors=True\n",
        ")\n",
        "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnYTob9AjvBz"
      },
      "outputs": [],
      "source": [
        "chain = MultiPromptChain(\n",
        "    router_chain=router_chain,\n",
        "    destination_chains=destination_chains,\n",
        "    default_chain=default_chain,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRM5M6ENjwxM"
      },
      "outputs": [],
      "source": [
        "print(chain.run(\"What is black body radiation?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Es-ftz6kjyTv"
      },
      "outputs": [],
      "source": [
        "print(\n",
        "    chain.run(\n",
        "        \"What is the first prime number greater than 40 such that one plus the prime number is divisible by 3\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrMo65z_kRW_"
      },
      "outputs": [],
      "source": [
        "print(chain.run(\"What is the name of the type of cloud that rins\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFQ5nJ3ekZxF"
      },
      "source": [
        "#EmbeddingRouterChain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvTbGXBjkql5"
      },
      "source": [
        "###loading the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiAVNI5dktDa"
      },
      "outputs": [],
      "source": [
        "!pip install sentence_transformers\n",
        "!pip install chromadb==0.3.29\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FX6LYpoRks8i"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain import VectorDBQA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uv9ON4HUks0W"
      },
      "outputs": [],
      "source": [
        "embeddings = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "#embeddings = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "# embeddings = SentenceTransformerEmbeddings(model_name=\"tiiuae/falcon-7b-instruct\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9zzm_OKkUj_"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.router.embedding_router import EmbeddingRouterChain\n",
        "# from langchain.embeddings import CohereEmbeddings\n",
        "from langchain.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMJM4KnWkdb9"
      },
      "outputs": [],
      "source": [
        "names_and_descriptions = [\n",
        "    (\"physics\", [\"for questions about physics\"]),\n",
        "    (\"math\", [\"for questions about math\"]),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYLPqnL5kemq"
      },
      "outputs": [],
      "source": [
        "router_chain = EmbeddingRouterChain.from_names_and_descriptions(\n",
        "    names_and_descriptions, Chroma, embeddings, routing_keys=[\"input\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VgpdYEFkhaT"
      },
      "outputs": [],
      "source": [
        "chain = MultiPromptChain(\n",
        "    router_chain=router_chain,\n",
        "    destination_chains=destination_chains,\n",
        "    default_chain=default_chain,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1fVL0BalZmm",
        "outputId": "488561b9-df4f-459a-a69c-4d4646535a4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "physics: {'input': 'What is black body radiation?'}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "A) A type of radiation that can be absorbed by all matter\n",
            "B) A type of radiation that can be emitted by all matter\n",
            "C) A type of radiation that can be both absorbed and emitted by all matter\n",
            "D) A type of radiation that is always absorbed by all matter\n",
            "\n",
            "Answer: D) A type of radiation that is always absorbed by all matter.\n"
          ]
        }
      ],
      "source": [
        "print(chain.run(\"What is black body radiation?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGl_jwvblbM9",
        "outputId": "2ed9ead1-43ad-4b71-f040-3177eb0d29eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "math: {'input': 'What is a set'}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " of 10 numbers between 1 and 100, where each number is 2 more than the previous number?\n",
            "\n",
            "You can answer this question by breaking it down into smaller parts. First, you need to find the first number in the set. This is 1. Then, you need to add 2 to get the next number, which is 3. So the next number in the set is 3. Then, you need to add 2 to get the next number, which is 5. So the next number in the set is 5. Then, you need to add 2 to get the next number, which is 7. So the next number in the set is 7. And so on until you reach 100.\n",
            "\n",
            "Once you have all the numbers, you can add them up to get the total sum of the set. The sum of the numbers in the set is 1000. Therefore, the set of 10 numbers between\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    chain.run(\n",
        "        \"What is a set\"\n",
        "    )\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPEp1Pcq3fnY5a69rdv2TrP",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
